{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivanleech/llm_evaluator/blob/main/llm_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4TFJbjtt2UX"
      },
      "source": [
        "# Using Trulens to evaluate LLM/RAG üîé\n",
        "\n",
        "üìì This notebook explores Advanced RAG methods using Direct Query as baseline, and compares them to sentence-window and automerging-retrieval methods.\n",
        "\n",
        "To evaluate the responses and context retrieved from various methods, we use TruLensüêô to explore a Triad of metrics, context relevance(context to query), answer relevance(answer to query) and groundedness(answer to context).\n",
        "\n",
        "Instead of using OpenAI, we use Ollama ü¶ô to install various models locally, allowing users without access to OpenAI to run these notebook without any issue. This notebook is recommend to run using Google Colab using the free T4 GPU compute. üñ•Ô∏è\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVRb4k_ovJB-"
      },
      "source": [
        "## 01 Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "J1KxKP0_NRjK"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!curl https://ollama.ai/install.sh | sh\n",
        "\n",
        "from trulens_eval import Tru\n",
        "tru = Tru()\n",
        "tru.reset_database()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RPUtFAr1pvNy"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from llama_index import Document\n",
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "# Downloads document and store as pdf locally\n",
        "url = 'https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf'\n",
        "file = 'attention.pdf'\n",
        "urllib.request.urlretrieve(url, file)\n",
        "\n",
        "# Create llama_index document which will be used to create index\n",
        "# The created index will provide context and used to answer questions using RAG later\n",
        "documents = SimpleDirectoryReader(input_files=[file]).load_data()\n",
        "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAFOhMVsro9p",
        "outputId": "7852b697-8cb8-46f0-c500-e129618753f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import os\n",
        "from time import sleep\n",
        "from subprocess import Popen\n",
        "from llama_index.embeddings import HuggingFaceEmbedding\n",
        "\n",
        "# Pull embedding llm and reranking llm from HuggingFace\n",
        "# model = 'dolphin-phi'\n",
        "model = 'llama2'\n",
        "base_url = 'http://localhost:11434'\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")\n",
        "reranker_model = \"BAAI/bge-reranker-base\"\n",
        "\n",
        "# Pulls model from Ollama. Will be used as evaluating llm and generating llm\n",
        "p = Popen([\"ollama\", \"serve\"])  # something long running\n",
        "sleep(1)\n",
        "os.system(f'ollama pull {model}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "f3b_WQokWeM4"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import Ollama\n",
        "from trulens_eval import LiteLLM\n",
        "import litellm\n",
        "litellm.set_verbose=False\n",
        "\n",
        "# 2 objects are created from the same model, 1 for generating answers, 1 for evaluating the RAG performance\n",
        "\n",
        "# Used by llama_index ServiceContext as generating llm\n",
        "ollama = Ollama(base_url=base_url, model=model)\n",
        "\n",
        "# Used by Trulens as evaluation llm\n",
        "ollama_provider = LiteLLM(model_engine=f\"ollama/{model}\", api_base=base_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "417K5_XcvQEJ"
      },
      "source": [
        "## 02 Advanced RAG\n",
        "\n",
        "Retrieval Augmented Generation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-7_-CHzvZdP"
      },
      "source": [
        "### Direct Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WHYS5qoFQ1fv"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "from llama_index import ServiceContext\n",
        "\n",
        "# Creates ServiceContext, which is a bundler to hold generating llm and embedding llm\n",
        "service_context = ServiceContext.from_defaults(llm=ollama, embed_model=embed_model)\n",
        "\n",
        "# VectorStoreIndex converts text from earlier document into embeddings using embedding llm\n",
        "# query_engine is created from the index, and is able to answer questions with context from the document\n",
        "index = VectorStoreIndex.from_documents([document], service_context=service_context)\n",
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1q_Yk2gvflN"
      },
      "source": [
        "## Sentence-window retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fj9CjFmmveS6"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import SentenceWindowNodeParser\n",
        "from llama_index import StorageContext\n",
        "from llama_index import load_index_from_storage\n",
        "\n",
        "# SentenceWindowNodeParser takes in parameters used to decide how the sentence window RAG is\n",
        "node_parser = SentenceWindowNodeParser.from_defaults(window_size=3, window_metadata_key=\"window\", original_text_metadata_key=\"original_text\")\n",
        "sentence_context = ServiceContext.from_defaults(llm=ollama, embed_model=embed_model, node_parser=node_parser)\n",
        "\n",
        "# Creates index if not found locally and save to local dir, load from local otherwise\n",
        "save_dir = 'sentence_index'\n",
        "if not os.path.exists(save_dir):\n",
        "    sentence_index = VectorStoreIndex.from_documents([document], service_context=sentence_context)\n",
        "    sentence_index.storage_context.persist(persist_dir=save_dir)\n",
        "else:\n",
        "    sentence_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=save_dir), service_context=sentence_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GE89SzKCxnWx"
      },
      "outputs": [],
      "source": [
        "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
        "from llama_index.indices.postprocessor import SentenceTransformerRerank\n",
        "\n",
        "rerank_top_n=2\n",
        "similarity_top_k=6\n",
        "\n",
        "# From index, retrieve top k documents most simlar to user query (i.e retrieve top 6 most similar documents)\n",
        "# From retrieved documents, rerank and get top n most relavant results to be used as context for RAG (i.e rerank and get top 2 most relavant results)\n",
        "postproc = MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
        "rerank = SentenceTransformerRerank(top_n=rerank_top_n, model=reranker_model)\n",
        "\n",
        "sentence_window_engine = sentence_index.as_query_engine(similarity_top_k=similarity_top_k, node_postprocessors=[postproc, rerank])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_qUOUrMy91z"
      },
      "source": [
        "## Automerging Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "P41RENWMzCYv"
      },
      "outputs": [],
      "source": [
        "from llama_index.node_parser import HierarchicalNodeParser\n",
        "from llama_index.node_parser import get_leaf_nodes\n",
        "\n",
        "\n",
        "chunk_sizes = [2048, 512, 128]\n",
        "node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "leaf_nodes = get_leaf_nodes(nodes)\n",
        "merging_context = ServiceContext.from_defaults(llm=ollama, embed_model=embed_model)\n",
        "storage_context = StorageContext.from_defaults()\n",
        "storage_context.docstore.add_documents(nodes)\n",
        "\n",
        "# Creates index if not found locally and save to local dir, load from local otherwise\n",
        "save_dir = 'merging_index'\n",
        "if not os.path.exists(save_dir):\n",
        "    automerging_index = VectorStoreIndex(leaf_nodes, storage_context=storage_context, service_context=merging_context)\n",
        "    automerging_index.storage_context.persist(persist_dir=save_dir)\n",
        "else:\n",
        "    automerging_index = load_index_from_storage(StorageContext.from_defaults(persist_dir=save_dir), service_context=merging_context,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_3YaAv8uz95H"
      },
      "outputs": [],
      "source": [
        "from llama_index.retrievers import AutoMergingRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# From leaf nodes, if insufficient context is found, parents nodes will be retrieved to provide context.\n",
        "# This will be repeated until sufficient context is found\n",
        "base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n",
        "retriever = AutoMergingRetriever(base_retriever, automerging_index.storage_context, verbose=True)\n",
        "rerank = SentenceTransformerRerank(top_n=rerank_top_n, model=reranker_model)\n",
        "auto_merging_engine = RetrieverQueryEngine.from_args(retriever, service_context=merging_context, node_postprocessors=[rerank])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p__1zXI1Khx"
      },
      "source": [
        "## 03 Use Trulens to evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhVwwURHsy6w",
        "outputId": "15c6b634-9561-4f95-d070-5f8cae212e58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "‚úÖ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
            "‚úÖ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
            "‚úÖ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
            "‚úÖ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
            "‚úÖ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from trulens_eval.feedback import Groundedness\n",
        "from trulens_eval import Feedback, TruLlama\n",
        "\n",
        "qa_relevance = (Feedback(ollama_provider.relevance_with_cot_reasons, name=\"Answer Relevance\")\n",
        "              .on_input_output())\n",
        "\n",
        "qs_relevance = (Feedback(ollama_provider.relevance_with_cot_reasons, name = \"Context Relevance\")\n",
        "              .on_input()\n",
        "              .on(TruLlama.select_source_nodes().node.text)\n",
        "              .aggregate(np.mean))\n",
        "\n",
        "grounded = Groundedness(groundedness_provider=ollama_provider)\n",
        "\n",
        "groundedness = (Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n",
        "              .on(TruLlama.select_source_nodes().node.text)\n",
        "              .on_output()\n",
        "              .aggregate(grounded.grounded_statements_aggregator))\n",
        "\n",
        "feedbacks = [qa_relevance, qs_relevance, groundedness]\n",
        "\n",
        "eval_questions = ['What is the paper about?', 'What is attention in context of the paper?', 'Who are the authors of the paper?']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install html2text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpNw4O74J-1n",
        "outputId": "28a6bc58-8f8b-45d2-9b55-583435935f7e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: html2text\n",
            "Successfully installed html2text-2020.1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDqM5gtlUgtJ",
        "outputId": "59f8d9cf-ba86-4354-9823-94c0febbc6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc567f40 is calling an instrumented method <function BaseQueryEngine.query at 0x7ce9c437ea70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8dc3059f0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc567f40 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7ce8f9438f70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8dc3059f0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x7ce8dc307d00 is calling an instrumented method <function BaseRetriever.retrieve at 0x7ce9c437dd80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app.retriever based on other object (0x7cea09969000) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.vector_stores.simple.SimpleVectorStore'> at 0x7ce8dc3e8370 is calling an instrumented method <function SimpleVectorStore.query at 0x7ce9c4109c60>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app.retriever._storage_context.vector_stores.default based on other object (0x7ce805b05510) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce9c0173310 is calling an instrumented method <function BaseSynthesizer.synthesize at 0x7ce9c43bff40>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8dc3e86a0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce9c0173310 is calling an instrumented method <function CompactAndRefine.get_response at 0x7ce9c41fcb80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8dc3e86a0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce9c0173310 is calling an instrumented method <function Refine.get_response at 0x7ce9c3b15480>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8dc3e86a0) using this function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the paper about?\n",
            "The paper \"Attention Is All You Need\" by Ashish Vaswani et al. discusses a new neural network architecture for sequence-to-sequence tasks, called the Transformer, which replaces traditional recurrent or convolutional layers with attention mechanisms. The Transformer is trained on machine translation tasks and achieves state-of-the-art results, outperforming previously published ensembles.\n",
            "\n",
            "The paper introduces a new attention mechanism called \"Scaled Dot-Product Attention,\" which computes the attention weights by taking the dot product of the query and key vectors, dividing each by the square root of the key dimension, and applying a softmax function. The paper also explores the use of multiple attention heads in parallel to jointly attend to information from different representation subspaces at different positions.\n",
            "\n",
            "The Transformer architecture consists of an encoder and a decoder, each composed of multiple layers. The encoder takes in a sequence of tokens (e.g., words or characters) and outputs a sequence of vectors, while the decoder generates a sequence of output tokens. Both the encoder and decoder use multi-head attention mechanisms to process the input sequence.\n",
            "\n",
            "The paper shows that the Transformer architecture can be trained significantly faster than previous architectures based on recurrent or convolutional layers, and achieves better performance on machine translation tasks. The authors also explore the use of attention mechanisms in other contexts, such as image generation and language modeling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc567f40 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7ce8f9438f70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8dc3059f0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce9c0173310 is calling an instrumented method <function CompactAndRefine.get_response at 0x7ce9c41fcb80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8dc3e86a0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce9c0173310 is calling an instrumented method <function Refine.get_response at 0x7ce9c3b15480>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8dc3e86a0) using this function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is attention in context of the paper?\n",
            "In the context of the paper, \"attention\" refers to a mechanism used in the Transformer architecture to allow the model to focus on different parts of the input sequence simultaneously and weigh their importance when computing the output. Attention was introduced as an alternative to traditional recurrent neural network (RNN) architectures, which process the input sequence sequentially and have limited capacity to capture long-range dependencies.\n",
            "\n",
            "In the Transformer architecture, attention is applied in three ways:\n",
            "\n",
            "1. Encoder-decoder attention: The queries come from the previous decoder layer, and the memory keys and values come from the output of the encoder. This allows every position in the decoder to attend over all positions in the input sequence.\n",
            "2. Self-attention layers in the encoder: Each position in the encoder can attend to all positions in the previous layer of the encoder.\n",
            "3. Self-attention layers in the decoder: Each position in the decoder can attend to all positions in the decoder up to and including that position.\n",
            "\n",
            "Attention is implemented using scaled dot-product attention, where each element in the input sequence is multiplied by a learnable weight and added to a linear transformation of the previous layer's output. The resulting vector is then passed through a softmax function to produce a probability distribution over the input sequence. This allows the model to selectively focus on different parts of the input sequence as it processes it.\n",
            "\n",
            "Overall, attention allows the Transformer architecture to efficiently capture long-range dependencies in the input sequence and generate more accurate output sequences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc567f40 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7ce8f9438f70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8dc3059f0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce9c0173310 is calling an instrumented method <function CompactAndRefine.get_response at 0x7ce9c41fcb80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8dc3e86a0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce9c0173310 is calling an instrumented method <function Refine.get_response at 0x7ce9c3b15480>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8dc3e86a0) using this function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who are the authors of the paper?\n",
            "The authors of the paper are:\n",
            "\n",
            "1. Sepp Hochreiter\n",
            "2. J√ºrgen Schmidhuber\n",
            "3. Rafal Jozefowicz\n",
            "4. Oriol Vinyals\n",
            "5. Mike Schuster\n",
            "6. Noam Shazeer\n",
            "7. Yonghui Wu\n",
            "8. ≈Åukasz Kaiser\n",
            "9. Ilya Sutskever\n",
            "\n",
            "These authors are known for their work in the field of natural language processing and deep learning, particularly in the area of transformer models.\n"
          ]
        }
      ],
      "source": [
        "tru_recorder = TruLlama(query_engine, app_id='Direct Query Engine', feedbacks=feedbacks)\n",
        "for question in eval_questions:\n",
        "    with tru_recorder as recording:\n",
        "        response = query_engine.query(question)\n",
        "        print(question)\n",
        "        print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "L4pZUfp31T1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4efb8365-54b5-46e2-840a-a0be0c7ff608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc7f0190 is calling an instrumented method <function BaseQueryEngine.query at 0x7ce9c437ea70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8fb6edd80) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc7f0190 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7ce8f9438f70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8fb6edd80) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> at 0x7ce8dc6b9180 is calling an instrumented method <function BaseRetriever.retrieve at 0x7ce9c437dd80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app.retriever based on other object (0x7ce918011ba0) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.vector_stores.simple.SimpleVectorStore'> at 0x7ce8f93fdc60 is calling an instrumented method <function SimpleVectorStore.query at 0x7ce9c4109c60>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app.retriever._index.storage_context.vector_stores.default based on other object (0x7ce9bfeb2830) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce8dc7f3370 is calling an instrumented method <function BaseSynthesizer.synthesize at 0x7ce9c43bff40>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8fb6efd30) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce8dc7f3370 is calling an instrumented method <function CompactAndRefine.get_response at 0x7ce9c41fcb80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8fb6efd30) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce8dc7f3370 is calling an instrumented method <function Refine.get_response at 0x7ce9c3b15480>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8fb6efd30) using this function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the paper about?\n",
            "Based on the provided context information, it appears that the paper being discussed is \"A Deep Reinforced Model for Abstractive Summarization\" by Romain Paulus, Caiming Xiong, and Richard Socher. The paper proposes a deep reinforcement learning model for abstractive summarization, which aims to generate summaries that are both concise and accurate. The model uses a combination of sequence-to-sequence and reinforcement learning techniques to learn the optimal policy for summarization.\n",
            "\n",
            "The paper also mentions other related work in the field of natural language processing, including the use of output embeddings to improve language models (as mentioned in [24]) and the concept of dropout as a regularization technique to prevent overfitting in neural networks (as mentioned in [27]).\n",
            "\n",
            "Overall, the paper appears to be focused on developing a new deep reinforcement learning model for abstractive summarization, while also providing context and background information on related work in the field.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc7f0190 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7ce8f9438f70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8fb6edd80) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce8dc7f3370 is calling an instrumented method <function CompactAndRefine.get_response at 0x7ce9c41fcb80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8fb6efd30) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce8dc7f3370 is calling an instrumented method <function Refine.get_response at 0x7ce9c3b15480>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8fb6efd30) using this function.\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is attention in context of the paper?\n",
            "Attention in the context of the paper refers to a mechanism used in various neural network models, including the Transformer, ConvS2S, and ByteNet, to relate signals from different positions in a sequence. Attention allows the model to focus on specific parts of the input sequence when computing representations or making predictions, enabling it to capture longer-range dependencies and better handle inputs with varying lengths.\n",
            "\n",
            "In the Transformer, attention is used entirely without recurrence or convolution, relying solely on self-attention to compute representations of its input and output. This allows the model to learn dependencies between distant positions in a more efficient manner than traditional sequence-aligned recurrent neural networks (RNNs) or convolutional neural networks (CNNs).\n",
            "\n",
            "In contrast, ConvS2S and ByteNet use attention mechanisms that grow in complexity with the distance between positions, which can make it more difficult to learn dependencies between distant parts of the input sequence. However, these models also use multi-head attention to counteract this effect, allowing them to capture longer-range dependencies while still using a constant number of operations.\n",
            "\n",
            "Overall, attention is an important component of many state-of-the-art neural network models, enabling them to effectively handle variable-length inputs and capture complex contextual relationships in sequential data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.query_engine.retriever_query_engine.RetrieverQueryEngine'> at 0x7ce8dc7f0190 is calling an instrumented method <function RetrieverQueryEngine.retrieve at 0x7ce8f9438f70>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app based on other object (0x7ce8fb6edd80) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce8dc7f3370 is calling an instrumented method <function CompactAndRefine.get_response at 0x7ce9c41fcb80>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8fb6efd30) using this function.\n",
            "WARNING:trulens_eval.app:A new object of type <class 'llama_index.response_synthesizers.compact_and_refine.CompactAndRefine'> at 0x7ce8dc7f3370 is calling an instrumented method <function Refine.get_response at 0x7ce9c3b15480>. The path of this call may be incorrect.\n",
            "WARNING:trulens_eval.app:Guessing path of new object is app._response_synthesizer based on other object (0x7ce8fb6efd30) using this function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who are the authors of the paper?\n",
            "Based on the provided context information, the authors of the paper \"Deep Residual Learning for Image Recognition\" are:\n",
            "\n",
            "1. Kaiming He\n",
            "2. Xiangyu Zhang\n",
            "3. Shaoqing Ren\n",
            "4. Jian Sun\n"
          ]
        }
      ],
      "source": [
        "tru_recorder_sentence_window = TruLlama(sentence_window_engine, app_id='Sentence Window Query Engine', feedbacks=feedbacks)\n",
        "for question in eval_questions:\n",
        "    with tru_recorder_sentence_window as recording:\n",
        "        response = sentence_window_engine.query(question)\n",
        "        print(question)\n",
        "        print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gsoKK1YW1UUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96ad06ee-72e6-4dab-b726-536a57d48d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the paper about?\n",
            "Based on the provided context information and the paper's PDF file path, it appears that the paper \"Attention Is All You Need\" is focused on a deep learning architecture called Transformer, which was introduced in 2017 by Vaswani et al. in the paper titled \"Attention Is All You Need\". The Transformer model relies entirely on self-attention mechanisms, eliminating the need for traditional recurrent neural networks (RNNs) or convolutional neural networks (CNNs).\n",
            "\n",
            "The paper presents a novel attention mechanism that allows the model to focus on different parts of the input sequence simultaneously and weigh their importance. This allows the model to capture long-range dependencies and contextual relationships in the input data, which is particularly useful for natural language processing tasks such as machine translation and text summarization.\n",
            "\n",
            "The paper also analyzes the performance of the Transformer model on several benchmark datasets and compares it to other state-of-the-art models. The results show that the Transformer model outperforms these other models in most cases, demonstrating its effectiveness and efficiency.\n",
            "\n",
            "Overall, the paper presents a significant contribution to the field of natural language processing by introducing a new attention mechanism that enables the Transformer model to capture long-range dependencies and contextual relationships in input data.\n",
            "What is attention in context of the paper?\n",
            "In the context of the paper, attention refers to a type of attention mechanism used in various natural language processing tasks, including reading comprehension, abstractive summarization, textual entailment, and learning task-independent sentence representations. This self-attention mechanism relates different positions of a single sequence to compute a representation of the sequence. The attention function maps a query and a set of key-value pairs to an output, where the output is computed as a weighted sum of the values, with the weights assigned by a compatibility function of the query with the corresponding key. End-to-end memory networks are also based on a recurrent attention mechanism instead of sequence-aligned recurrence, which has been shown to perform well on simple-language question answering and language modeling tasks.\n",
            "Who are the authors of the paper?\n",
            "Based on the provided context information, the authors of the paper \"Neural Machine Translation of Rare Words with Subword Units\" are Rico Sennrich, Barry Haddow, and Alexandra Birch.\n"
          ]
        }
      ],
      "source": [
        "tru_recorder_automerging = TruLlama(auto_merging_engine, app_id='Automerging Query Engine', feedbacks=feedbacks)\n",
        "for question in eval_questions:\n",
        "    with tru_recorder_automerging as recording:\n",
        "        response = auto_merging_engine.query(question)\n",
        "        print(question)\n",
        "        print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tHvpiji9jNV1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "8df1c317-0298-40e2-b032-9329fa4321a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                              Context Relevance  Groundedness  \\\n",
              "app_id                                                          \n",
              "Automerging Query Engine               0.950000      1.000000   \n",
              "Direct Query Engine                    0.666667      0.500000   \n",
              "Sentence Window Query Engine           0.600000      0.777778   \n",
              "\n",
              "                              Answer Relevance  latency  total_cost  \n",
              "app_id                                                               \n",
              "Automerging Query Engine                   0.9     43.0         0.0  \n",
              "Direct Query Engine                        0.3     43.0         0.0  \n",
              "Sentence Window Query Engine               0.3     43.0         0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79eee79a-35c3-4f49-ab27-7347a0fda20a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context Relevance</th>\n",
              "      <th>Groundedness</th>\n",
              "      <th>Answer Relevance</th>\n",
              "      <th>latency</th>\n",
              "      <th>total_cost</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>app_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Automerging Query Engine</th>\n",
              "      <td>0.950000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.9</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Direct Query Engine</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.3</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentence Window Query Engine</th>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.3</td>\n",
              "      <td>43.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79eee79a-35c3-4f49-ab27-7347a0fda20a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79eee79a-35c3-4f49-ab27-7347a0fda20a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79eee79a-35c3-4f49-ab27-7347a0fda20a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-527d6be0-4960-45a4-a82f-ac014e3630b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-527d6be0-4960-45a4-a82f-ac014e3630b7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-527d6be0-4960-45a4-a82f-ac014e3630b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tru.get_leaderboard(app_ids=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xqVm3ZIG6O2g"
      },
      "outputs": [],
      "source": [
        "# tru.get_records_and_feedback(app_ids=[])[0] # pass an empty list of app_ids to get all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tMM_QqnX5cgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab1506c-080b-45cc-9ee6-c79bc002c558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.16.162.186"
          ]
        }
      ],
      "source": [
        "!curl ipecho.net/plain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "m87eUEETsGkM",
        "outputId": "5aa17bbf-61ac-4150-b84a-4bb385874e87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dashboard closed.\n",
            "Dashboard closed.\n",
            "Starting dashboard ...\n",
            "Config file already exists. Skipping writing process.\n",
            "Credentials file already exists. Skipping writing process.\n",
            "npx: installed 22 in 5.543s\n",
            "\n",
            "Go to this url and submit the ip given here. your url is: https://social-rooms-sort.loca.lt\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dashboard failed to start in time. Please inspect dashboard logs for additional information.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-1623da16bf14>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# click the url provided and key in above ip in the box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtru\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_dashboard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trulens_eval/tru.py\u001b[0m in \u001b[0;36mrun_dashboard\u001b[0;34m(self, port, address, force, _dev)\u001b[0m\n\u001b[1;32m    678\u001b[0m         if not started.wait(timeout=wait_period\n\u001b[1;32m    679\u001b[0m                            ):  # This might not work on windows.\n\u001b[0;32m--> 680\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    681\u001b[0m                 \u001b[0;34m\"Dashboard failed to start in time. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;34m\"Please inspect dashboard logs for additional information.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dashboard failed to start in time. Please inspect dashboard logs for additional information."
          ]
        }
      ],
      "source": [
        "try:\n",
        "  tru.stop_dashboard()\n",
        "except:\n",
        "  pass\n",
        "sleep(5)\n",
        "# click the url provided and key in above ip in the box\n",
        "tru.run_dashboard(port=8501)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkI_1uruB8CT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmLDia+T8HYOOCTT40L4/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}